<!DOCTYPE html>
<html>
<head>
	<meta content="en-us" http-equiv="Content-Language">
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
	<title>Yu Cao </title>
	<meta charset="utf-8">
</head>
<body leftmargin="40" bgcolor="#FFFFFF" link="#444444" text="#444444">
	<table border="0" id="table1" width="720">
		<tbody>
			<tr>
				<td width="323">
					<p align="center"><font face="Arial"><img border="0" src="yucao.jpeg"></font></p>
				</td>
				<td>
					<font face="Arial" size="5"><b>&nbsp;Yu Cao <span lang="zh-cn">曹宇</span></b></font>
					<p><font face="Arial" style="font-size: 11pt;">&nbsp; Research Engineer</font></p>
					<p><font face="Arial" style="font-size: 11pt;">&nbsp; Bloomberg Engineering, New York, New York</font></p>
				</td>
			</tr>
		</tbody>
	</table>
	<table border="1" style="border-width: 0px;" width="760">
		<tbody>
			<tr>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px;"><font face="Arial" style="font-size: 12pt;">I am a Research Engineer/Senior Software Engineer in  Bloomberg focused on developing pricing algorithms for fix-income market. Before Bloomberg, I did my master with research on distributed systems in Computer Science Department, Courant Institute of Mathematical Sciences, New York University. Prior to NYU, I had my B.E and M.S in Beihang University.<br>
					<br>
					Before coming to NYU, my research interest was in machine vision applying conventional geometry and computer vision using machine learning methods. My master thesis is on the topic of Indoor Navigation Oriented Visual SLAM Technology. I spent a great half year on internship in Face++. Now I am with the NYU system group.
				</td>
			</tr>
		</tbody>
	</table><br>

	<br></font></p>

	<p><b><font face="Arial" size="4"><br>
	Updates</font></b></p>
	<ul>
		<li>
			<p><font face="Arial">Research Intern for  </font>at <font face="Arial"><a href="https://www.bytedance.com/en/"><font color="#444444"><font face="Arial"><font color="#444444">Bytedance</font></font></font></a> Applied Machine Learning Systems team for optimizing resource efficiency for large sccale DNN inference service.<br>
			</font></p>
		</li>
		<li>
			<p><font face="Arial">Teaching Assistant for  </font>at <font face="Arial"><a href="http://www.news.cs.nyu.edu/~jinyang/fa19-ds/"><font color="#444444"><font face="Arial"><font color="#444444">Distributed Systems</font></font></font></a> graduate class for NYU CS.<br>
			</font></p>
		</li>
		<li>
			<p><font face="Arial">Applied scientist intern in AWS AI </font>at <font face="Arial"><a href="https://aws.amazon.com/rekognition/"><font color="#444444"><font face="Arial"><font color="#444444">Rekognition Team</font></font></font></a> developing deep learning methods for multi-lingual text detection.<br>
			</font></p>
		</li>
		<li>
			<p><font face="Arial">Competition </font> <font face="Arial"><b>Winner</b> of <font face="Arial"><a href="https://research.google.com/ava/challenge.html"><font color="#444444"><font face="Arial"><font color="#444444">Atomic Video Action Recognition Challenge in CVPR 2018 Workshop</font></font></font></a> with human action recognition mean Average Precision of 0.2108.<br>
			</font></p>
		</li>
	</ul>
	<p></p>
	<meta charset="utf-8">
	<meta charset="utf-8">
	<p></p>
	<p></p>
	<p class="style4"><br></p>
	<p><b><font face="Arial" size="4">Publications and tech report</font></b></p>
	<table border="1" id="table2" style="border-width: 0px;" width="1154">
		<tbody>
			<tr>
				<td style="border-style: none; border-width: medium;" valign="top" width="19">&nbsp;</td>
				<td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="14">&nbsp;</td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Fast and Resource-efficient Hardware Implementation of Modified Line Segment Detector</font></i><br>
					<font color="#000000" face="Arial" size="2">Fuqiang Zhou<sup>*</sup>, <b>Yu Cao<sup>*</sup></b>, Xinming Wang</font><br>
					<font face="Arial" size="2">IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2018</font><br>
					<a href="https://ieeexplore.ieee.org/document/8022954"><font color="#808080" face="Arial" size="2">IEEE</font></a></p>
				</td>
			</tr>
			<tr>
				<td style="border-style: none; border-width: medium;" valign="top" width="19">&nbsp;</td>
				<td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="14">&nbsp;</td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Minimal Non-Linear Camera Pose Estimation Method Using Lines for SLAM Application</font></i><br>
					<font color="#000000" face="Arial" size="2"><b>Yu Cao</b>, Haishu Tan, Fuqiang Zhou </font><br>
					<font face="Arial" size="2"> IEEE Winter Conference on Applications of Computer Vision  (<b>WACV</b>), 2018 (<b>Oral</b>). <a href="https://eccv2018.org/news/eccv-awards/"></a></font><br>
					<a href="https://ieeexplore.ieee.org/document/8354213"><font color="#808080" face="Arial" size="2">IEEE</font></a>
				  </p>
				</td>
			</tr>
			<tr>
				<td style="border-style: none; border-width: medium;" valign="top" width="19">&nbsp;</td>
				<td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="14">&nbsp;</td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Human Centric Spatio-Temporal Action Localization</font></i><br>
					<font color="#000000" face="Arial" size="2">Jianwen Jiang, <b>Yu Cao</b>, Lin Song, Shiwei Zhang, Yunkai Li, Ziyao Xu, Qian Wu, Chuang Gan, Chi Zhang, Gang Yu</font><br>
					<font face="Arial" size="2"> Tech Report of ActivityNet Large Scale Activity Recognition Challenge 2018 (<b>CVPRW</b>), 2018. <a href="http://activity-net.org/challenges/2018/index.html"></a></font><br>
					<a href="https://static.googleusercontent.com/media/research.google.com/en//ava/2018/Human_Centric_Spatio-Temporal_Action_Localization.pdf"><font color="#808080" face="Arial" size="2">pdf</font></a>
				  </p>
				</td>
			</tr>
		</tbody>
	</table>
</body>
</html>


